{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第一章 统计学习及监督学习概论"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1  统计学习\n",
    "① 统计学习由监督学习(样本有标签，如分类问题)、非监督学习（如样本无标签下的分类）、半监督学习（部分样本有标签，部分没有）、主动学习和强化学习等组成\n",
    "\n",
    "② 统计学习方法<br>\n",
    "&emsp;A.从给定的、有限的、用于学习的训练数据(training set)集合出发<br>\n",
    "&emsp;B.假设数据是独立同分布的<br>\n",
    "&emsp;C.假设要学习的模型属于某个函数的集合，称为假设空间<br>\n",
    "&emsp;D.应用某个评价准则（损失函数、经验风险），从假设空间中选取一个最优的模型；这个模型使它对已知训练数据及未知测试数据在给定的预测准则下有最优预测<br>\n",
    "&emsp;E.最优模型的选取由算法（梯度下降(求偏导)）实现<br>\n",
    "\n",
    "③ 统计学习方法的步骤<br>\n",
    "&emsp;A.得到一个有限的训练数据集合<br>\n",
    "&emsp;B.确定包含所有可能的模型假设空间，即学习模型的集合<br>\n",
    "&emsp;C.确定模型选择的准则，即学习的策略<br>\n",
    "&emsp;D.实现求解最优模型的算法，即学习的算法<br>\n",
    "&emsp;E.通过学习方法选择最优模型<br>\n",
    "&emsp;F.利用学的最优模型对寻数据进行预测或分析<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 统计学习方法的分类\n",
    "### 1.2.1 基本分类\n",
    "#### ① 监督学习\n",
    "**输入空间**：将输入所有可能数值的集合成为输入空间<br>\n",
    "**输出空间**：将输出所有可能数值的集合成为输出空间，通常输出空间远远小于输入空间<br>\n",
    "**特征空间**：每个具体的输入是一个实例，通常由特征向量表示。所有特征向量的集合成为特征空间，特征空间的每一维对应一个特征。\n",
    "$$x_{1}表示第一个样本，而 x^{1}_{1}第一个样本的第一个特征（下表代表样本，上标代表特征）$$\n",
    "监督学习从训练集合中学习模型，对测试数据进行预测，训练数据由输入（或者特征空间）于输出对组成，训练集通常表示为\n",
    "$$T = \\lbrace(x_{1},y_{1}),(x_{2},y_{2}),\\dots,(x_{n},y_{n})\\rbrace$$\n",
    "测试数据也由相应的**输入输出对**组成，**输入输出数据又称为样本或者样本点。**<br>\n",
    "\n",
    "**联合概率分布**：监督学习假设输入于输出的随机变量x和y遵循联合概率分布P(X,Y)。P(X,Y)表示分布函数，或者分布密度函数。\n",
    "**假设空间**：监督学习的目的在于学习一个由输入到输出的**映射**，这一映射由**模型**表示。模型属于由输入空间到输出空间的的映射的集合，这个集合就是假设空间。(假设空间中有多个模型，通过损失函数、经验风险筛选)\n",
    "概率模型/条件概率分布:$$P(y\\mid x)$$\n",
    "非概率模型/决策函数：$$y = f(x)$$\n",
    "注：对于二维随机变量(X,Y)，可以考虑在其中一个随机变量取得（可能的）固定值的条件下，另一随机变量的概率分布，这样得到的X或Y的概率分布叫做**条件概率分布**，简称条件分布。<br>\n",
    "问题的形式化：书中图1.1。两种模型的预测取值方式略有不同\n",
    "\n",
    "#### ② 无监督学习\n",
    "无监督学习是值从无标注的数据中预测模型的机器学习问题。无标注数据是自然得到的数据，预测模型表示数据的类别、转换和概率。<br>\n",
    "每一个输出是对输入的分析结果，由输入的类别、转换或概率表达。模型可以实现对数据的聚类、降维和概率估计。<br>\n",
    "无监督学习的模型：函数z = g<sub>θ</sub>(x)(硬聚类)、条件概率分布P<sub>θ</sub>(z|x)（软聚类）或条件概率分布P<sub>θ</sub>(x|z)（概率模型估计）<br>\n",
    "参考链接：https://zhuanlan.zhihu.com/p/94614824<br>\n",
    "问题的形式化：图1.2\n",
    "\n",
    "#### ③ 强化学习\n",
    "强化学习是指智能系统在与环境的连续互动中学习最优行为策略的机器学习问题。<br>\n",
    "智能系统的目标不是短期奖励的最大化，而是长期积累奖励的最大化。<br>\n",
    "**知乎**：能否介绍一下强化学习（Reinforcement Learning），以及与监督学习的不同？--https://www.zhihu.com/question/41775291\n",
    "强化学习的马尔可夫决策郭诚是状态、奖励、动作序列上的随机过程，由五个元组组成（状态、动作、状态转移概率、奖励函数和衰减函数）。马尔可夫决策具有马尔可夫性，下一个状态只依赖于前一个转台与动作，由状态转移概率函数P(s'|s,a)表示。下一个奖励依赖于前一个状态与动作，由奖励函数r(s,a)表示。<br>\n",
    "强化学习方法分为有模型的方法和无模型的方法：<br>\n",
    "&emsp;有模型的方法试图直接学习马尔可夫决策过程的模型，包裹转移概率函数P(s'|s,a)和奖励函数r(s,a)。通过模型对环境的反馈进行预测，求出价值函数最大的策略Π<sup>*</sup>。<br>\n",
    "&emsp;无模型的、基于策略的方法不直接学习模型，而是试图求解最优策略Π<sup>*</sup>，表示为函数a = f<sup>*</sup>(s)或者是条件概率分布P<sup>*</sup>(a|s)（例：百面机器学习P262）<br>\n",
    "&emsp;无模型的、基于价值的方法也不直接学习模型，二十试图求解最优价值函数，特别是最优动作价值函数q<sup>*</sup>(s,a)。(例：百面机器学习算法P260，用到贝尔曼方程)<br>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "严格来说没有完成既定任务，尽快补上！ </div>"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
